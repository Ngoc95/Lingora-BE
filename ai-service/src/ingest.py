import os
import shutil
from langchain_openai import OpenAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from src.config.env import settings

# --- Cáº¤U HÃŒNH ---
FILES_TO_PROCESS = {
    "english_grammar_in_use.pdf": "grammar_collection",
    "english_vocabulary_in_use.pdf": "vocab_collection"
}

def ensure_pdf_exists(file_name: str) -> bool:
    """Kiá»ƒm tra vÃ  táº£i PDF náº¿u chÆ°a cÃ³"""
    file_path = os.path.join(settings.DATA_PATH, file_name)
    
    if os.path.exists(file_path):
        return True
    
    print(f"âš ï¸  File {file_name} khÃ´ng tÃ¬m tháº¥y. Äang thá»­ táº£i tá»« Google Drive...")
    try:
        # Import vÃ  cháº¡y download script
        from scripts.download_data import download_file, PDF_URLS, convert_google_drive_link
        
        if file_name in PDF_URLS and PDF_URLS[file_name]:
            url = PDF_URLS[file_name]
            download_file(convert_google_drive_link(url), file_path)
            return True
        else:
            print(f"âŒ KhÃ´ng cÃ³ URL cho {file_name} trong .env")
            print(f"   Vui lÃ²ng set {'GRAMMAR_PDF_URL' if 'grammar' in file_name else 'VOCAB_PDF_URL'} trong .env")
            return False
    except Exception as e:
        print(f"âŒ Lá»—i khi táº£i {file_name}: {e}")
        return False

def process_pdf(file_name, collection_name):
    # Kiá»ƒm tra vÃ  táº£i PDF náº¿u cáº§n
    if not ensure_pdf_exists(file_name):
        print(f"â­ï¸  Bá» qua {file_name}")
        return
    
    file_path = os.path.join(settings.DATA_PATH, file_name)
    
    print(f"\nğŸ”„ Äang xá»­ lÃ½: {file_name} -> Collection: {collection_name}")

    # 1. Load PDF
    loader = PyPDFLoader(file_path)
    documents = loader.load()
    print(f"   - ÄÃ£ Ä‘á»c xong {len(documents)} trang.")

    # 2. Cáº¯t nhá» vÄƒn báº£n (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"   - ÄÃ£ chia thÃ nh {len(chunks)} Ä‘oáº¡n nhá».")

    # 3. Táº¡o Embeddings (DÃ™NG OPENAI)
    print("   - Äang táº¡o embeddings vá»›i OpenAI...")
    embeddings = OpenAIEmbeddings(
        openai_api_key=settings.OPENAI_API_KEY,
        model="text-embedding-3-small"  # Hoáº·c "text-embedding-ada-002" (ráº» hÆ¡n) hoáº·c "text-embedding-3-large" (tá»‘t hÆ¡n)
    )

    # 4. LÆ°u vÃ o ChromaDB
    vector_store = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=settings.CHROMA_DB_DIR,
        collection_name=collection_name
    )
    
    print(f"âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng vÃ o ChromaDB táº¡i: {settings.CHROMA_DB_DIR}")

def main():
    print("ğŸš€ Báº®T Äáº¦U QUÃ TRÃŒNH Náº P Dá»® LIá»†U...")
    
    # XÃ³a DB cÅ© náº¿u Ä‘á»•i tá»« HuggingFace sang OpenAI (vÃ¬ embeddings khÃ¡c nhau)
    # if os.path.exists(settings.CHROMA_DB_DIR):
    #     print("âš ï¸  PhÃ¡t hiá»‡n ChromaDB cÅ©. VÃ¬ Ä‘Ã£ Ä‘á»•i sang OpenAI embeddings,")
    #     print("   cáº§n náº¡p láº¡i tá»« Ä‘áº§u. Äang xÃ³a DB cÅ©...")
    #     shutil.rmtree(settings.CHROMA_DB_DIR)
    #     print("âœ… ÄÃ£ xÃ³a DB cÅ©.")
    
    for file_name, collection_name in FILES_TO_PROCESS.items():
        process_pdf(file_name, collection_name)

    print("\nğŸ‰ HOÃ€N Táº¤T! Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.")

if __name__ == "__main__":
    main()