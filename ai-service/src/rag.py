from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_tavily import TavilySearch
from langchain_core.tools import tool
from langchain_classic.agents import create_openai_functions_agent, AgentExecutor # Import tr·ª±c ti·∫øp t·ª´ file g·ªëc
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.globals import set_llm_cache
from langchain_community.cache import InMemoryCache
from src.config.env import settings
import os

# --- 1. C·∫§U H√åNH C∆† B·∫¢N ---
# Setup Tavily Key
os.environ["TAVILY_API_KEY"] = settings.TAVILY_API_KEY

set_llm_cache(InMemoryCache())

# Setup Embeddings
embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    model_kwargs={'device': 'cpu'}
)

# Setup LLM (Gemini)
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", # Ho·∫∑c 1.5-flash
    google_api_key=settings.GOOGLE_API_KEY,
    temperature=0 # ƒê·ªÉ Agent ra quy·∫øt ƒë·ªãnh ch√≠nh x√°c, n√™n ƒë·ªÉ temp th·∫•p
)

# --- 2. B·ªò NH·ªö (MEMORY) ---
# V·∫´n d√πng c√°ch l∆∞u dictionary ƒë∆°n gi·∫£n c·ªßa b·∫°n, nh∆∞ng t√≠ n·ªØa s·∫Ω convert
CHAT_HISTORY = {}

def get_chat_history(session_id):
    return CHAT_HISTORY.get(session_id, [])

def save_chat_history(session_id, question, answer):
    if session_id not in CHAT_HISTORY: CHAT_HISTORY[session_id] = []
    CHAT_HISTORY[session_id].append((question, answer))
    if len(CHAT_HISTORY[session_id]) > 10: CHAT_HISTORY[session_id].pop(0)

# --- 3. ƒê·ªäNH NGHƒ®A C√îNG C·ª§ (TOOLS) ---
# Agent s·∫Ω nh√¨n v√†o docstring ("""...""") ƒë·ªÉ bi·∫øt khi n√†o d√πng tool n√†o.

@tool
def lookup_grammar_book(query: str):
    """
    D√πng c√¥ng c·ª• n√†y ƒë·ªÉ tra c·ª©u ki·∫øn th·ª©c v·ªÅ Ng·ªØ ph√°p Ti·∫øng Anh (Grammar), 
    c·∫•u tr√∫c c√¢u (Sentence Structure), c√°c th√¨ (Tenses) trong s√°ch gi√°o khoa.
    """
    print(f"üìò [Tool] ƒêang tra s√°ch Ng·ªØ ph√°p: {query}")
    try:
        vector_store = Chroma(
            persist_directory=settings.CHROMA_DB_DIR,
            embedding_function=embedding_model,
            collection_name="grammar_collection"
        )
        retriever = vector_store.as_retriever(search_kwargs={"k": 4})
        docs = retriever.invoke(query)
        return "\n\n".join([doc.page_content for doc in docs])
    except Exception as e:
        print(f"‚ùå L·ªói khi tra s√°ch Ng·ªØ ph√°p: {e}")
        return "S√°ch gi√°o khoa kh√¥ng ƒë·ªÅ c·∫≠p chi ti·∫øt. H√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c chuy√™n m√¥n c·ªßa b·∫°n ƒë·ªÉ gi·∫£i th√≠ch ƒë·∫ßy ƒë·ªß cho h·ªçc vi√™n."

@tool
def lookup_vocab_book(query: str):
    """
    D√πng c√¥ng c·ª• n√†y ƒë·ªÉ tra c·ª©u T·ª´ v·ª±ng (Vocabulary), ƒë·ªãnh nghƒ©a t·ª´ (Definition),
    th√†nh ng·ªØ (Idioms) ho·∫∑c c·ª•m t·ª´ trong s√°ch gi√°o khoa.
    """
    print(f"üìó [Tool] ƒêang tra s√°ch T·ª´ v·ª±ng: {query}")
    try:
        vector_store = Chroma(
            persist_directory=settings.CHROMA_DB_DIR,
            embedding_function=embedding_model,
            collection_name="vocab_collection"
        )
        retriever = vector_store.as_retriever(search_kwargs={"k": 4})
        docs = retriever.invoke(query)
        return "\n\n".join([doc.page_content for doc in docs])
    except Exception as e:
        print(f"‚ùå L·ªói khi tra s√°ch T·ª´ v·ª±ng: {e}")
        return "S√°ch gi√°o khoa kh√¥ng ƒë·ªÅ c·∫≠p chi ti·∫øt. H√£y s·ª≠ d·ª•ng ki·∫øn th·ª©c chuy√™n m√¥n c·ªßa b·∫°n ƒë·ªÉ gi·∫£i th√≠ch ƒë·∫ßy ƒë·ªß cho h·ªçc vi√™n."

# Tool Search Google (Tavily)
search_web_tool = TavilySearch(
    max_results=3,
    description="D√πng c√¥ng c·ª• n√†y ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin KH√îNG c√≥ trong s√°ch gi√°o khoa, ki·∫øn th·ª©c x√£ h·ªôi, ho·∫∑c c√°c t·ª´ l√≥ng (slang) m·ªõi nh·∫•t."
)

# Gom t·∫•t c·∫£ tools l·∫°i
tools = [lookup_grammar_book, lookup_vocab_book, search_web_tool]

# --- 4. T·∫†O AGENT ---
def create_lingora_agent():
    # Prompt System cho Agent
    system_prompt = """
    B·∫°n l√† Lingora - Tr·ª£ l√Ω ·∫£o d·∫°y Ti·∫øng Anh th√¥ng minh.
    B·∫°n c√≥ 3 c√¥ng c·ª•: S√°ch Ng·ªØ Ph√°p, S√°ch T·ª´ V·ª±ng, Google Search.

    NHI·ªÜM V·ª§ C·ª¶A B·∫†N:
    1. Nh·∫≠n c√¢u h·ªèi t·ª´ h·ªçc vi√™n.
    2. QUY·∫æT ƒê·ªäNH xem n√™n d√πng c√¥ng c·ª• n√†o:
       - N·∫øu h·ªèi v·ªÅ ng·ªØ ph√°p -> D√πng 'lookup_grammar_book'.
       - N·∫øu h·ªèi v·ªÅ t·ª´ v·ª±ng -> D√πng 'lookup_vocab_book'.
       - N·∫øu h·ªèi v·ªÅ ki·∫øn th·ª©c ngo√†i l·ªÅ ho·∫∑c s√°ch kh√¥ng c√≥ -> D√πng 'tavily_search_results_json'.
       - N·∫øu l√† ch√†o h·ªèi x√£ giao (Hello, Hi) -> KH√îNG d√πng tool, t·ª± tr·∫£ l·ªùi th√¢n thi·ªán, vui v·∫ª, nh·∫π nh√†ng.
    
    QUY T·∫ÆC TR·∫¢ L·ªúI (QUAN TR·ªåNG):
    - Tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát t·ª± nhi√™n.
    - **TUY·ªÜT ƒê·ªêI KH√îNG XIN L·ªñI** n·∫øu kh√¥ng t√¨m th·∫•y trong s√°ch. C·ª© th·∫ø m√† tr·∫£ l·ªùi b·∫±ng ki·∫øn th·ª©c c·ªßa b·∫°n.
    - **KH√îNG NH·∫ÆC T√äN C√îNG C·ª§** (V√≠ d·ª•: ƒê·ª´ng n√≥i "C√¥ng c·ª• tra c·ª©u kh√¥ng c√≥...", "Theo Tavily...").
    - N·∫øu th√¥ng tin l·∫•y t·ª´ s√°ch, h√£y gi·∫£i th√≠ch chi ti·∫øt.

    SAU KHI C√ì TH√îNG TIN T·ª™ TOOL:
    - Tr·∫£ l·ªùi h·ªçc vi√™n b·∫±ng Ti·∫øng Vi·ªát.
    - Tr·∫£ l·ªùi t·ª± nhi√™n, kh√¥ng nh·∫Øc t√™n c√¥ng c·ª• (VD: ƒê·ª´ng n√≥i "Theo k·∫øt qu·∫£ Tavily...").
    - N·∫øu th√¥ng tin l·∫•y t·ª´ s√°ch, h√£y gi·∫£i th√≠ch chi ti·∫øt.
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="chat_history"), # N∆°i nh√©t l·ªãch s·ª≠ v√†o
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"), # N∆°i Agent suy nghƒ©
    ])

    # T·∫°o Agent
    agent = create_openai_functions_agent(llm, tools, prompt)
    
    # Executor l√† b·ªô m√°y ch·∫°y Agent
    agent_executor = AgentExecutor(
        agent=agent, 
        tools=tools, 
        verbose=True, # B·∫≠t True ƒë·ªÉ nh√¨n th·∫•y suy nghƒ© c·ªßa Agent tr√™n terminal
        handle_parsing_errors=True
    )
    return agent_executor

# Kh·ªüi t·∫°o 1 l·∫ßn d√πng chung
lingora_agent = create_lingora_agent()

# --- 5. H√ÄM CH√çNH (ƒê∆Ø·ª¢C G·ªåI T·ª™ API) ---
def get_answer(question: str, type: str = None, session_id: str = "default"):
    # 1. L·∫•y l·ªãch s·ª≠ chat th√¥
    raw_history = get_chat_history(session_id)
    
    # 2. Chuy·ªÉn ƒë·ªïi sang format c·ªßa LangChain (Memory c·ªßa Agent)
    lc_history = []
    for q, a in raw_history:
        lc_history.append(HumanMessage(content=q))
        lc_history.append(AIMessage(content=a))
    
    print(f"ü§ñ Agent ƒëang suy nghƒ© cho session: {session_id}...")

    try:
        # 3. Ch·∫°y Agent
        result = lingora_agent.invoke({
            "input": question,
            "chat_history": lc_history
        })
        
        raw_output = result['output']
        final_response = ""
        # Tr∆∞·ªùng h·ª£p 1: N√≥ tr·∫£ v·ªÅ chu·ªói b√¨nh th∆∞·ªùng (Ngon)
        if isinstance(raw_output, str):
            final_response = raw_output
            
        # Tr∆∞·ªùng h·ª£p 2: N√≥ tr·∫£ v·ªÅ List (nh∆∞ c√°i l·ªói b·∫°n g·∫∑p)
        elif isinstance(raw_output, list):
            for part in raw_output:
                # N·∫øu l√† chu·ªói th√¨ c·ªông v√†o
                if isinstance(part, str):
                    final_response += part
                # N·∫øu l√† Dictionary (c√≥ ch·ª©a 'text') th√¨ l·∫•y ph·∫ßn text
                elif isinstance(part, dict) and 'text' in part:
                    final_response += part['text']
        
        # Tr∆∞·ªùng h·ª£p 3: N√≥ tr·∫£ v·ªÅ Object l·∫° -> √âp sang string
        else:
            final_response = str(raw_output)
        # 4. L∆∞u l·∫°i l·ªãch s·ª≠
        save_chat_history(session_id, question, final_response)
        
        return final_response

    except Exception as e:
        print(f"‚ùå Agent Error: {e}")
        return "Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p ch√∫t tr·ª•c tr·∫∑c khi suy nghƒ©. B·∫°n h·ªèi l·∫°i th·ª≠ xem?"